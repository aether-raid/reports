{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AETHER Reports","text":"<p>Welcome to the AETHER Reports website!</p>"},{"location":"a-primer-on-brain-foundation-models/","title":"A Primer on Brain Foundation Models","text":"<p>In the past few years, computational neuroscience and cognitive sciences have slowly been catching up to major developments in AI over the past decade, slowly adopting various technologies such as variational autoencoders (1), diffusion learning (2), and most recently, foundation models. This work has since led to the tremendous development of what we now call brain foundation models.</p> <ol> <li>Bethge et al. used variational autoencoders to transform EEG data into a latent space representation to effectively understand various internal relationships.</li> <li>Zhou et al. used diffusion learning to increase the resolution of EEG channels to translate to higher-resolution EEG data.</li> </ol> <p>The promise of brain foundation models, or BFMs for short, is simple: generically modelling the relationship of various input channels via a large amount of raw data. Be it drivers on a simulator, or gamers playing Atari, be it athletes playing memory games, or traffic operators in their daily operations, we can collect data from all across this domain, from sensors far and wide, and feed them all into a foundation model, allowing it to learn and find relations that normal models accepting specific inputs simply cannot.</p>"},{"location":"archive/2025/","title":"2025","text":""},{"location":"category/cognition/","title":"Cognition","text":""}]}